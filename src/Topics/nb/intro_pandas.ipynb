{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/mottaquikarim/PYTH2/blob/master/src/Topics/nb/intro_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Pandas Objects\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/EatwJZRUIv41G/giphy.gif\" style=\"margin: 0 auto; float: right;\"/>\n",
    "\n",
    "**Pandas** is an open-source Python library of data structures and tools for exploratory data analysis (EDA). Pandas primarily facilitates acquisition, cleaning, formatting, and manipulating. Used in tandem with NumPy, Matplotlib, SciPy, and other Python libraries, Pandas is an integral part of practicing data science.\n",
    "\n",
    "To gain some baseline familiarity with Pandas features and pre-requisites, in this lesson, you'll learn about:\n",
    "\n",
    "* [Capabilities of Pandas](intro_pandas.md#capabilities-of-pandas)\n",
    "* [NumPy ndarray Objects](intro_pandas.md#numpy-ndarrays-objects)\n",
    "* [Basic Pandas Objects](intro_pandas.md#basic-pandas-objects)\n",
    "\t* [Index](intro_pandas.md#basic-pandas-objects-index)\n",
    "\t* [Series](intro_pandas.md#basic-pandas-objects-series)\n",
    "\t* [DataFrames](intro_pandas.md#basic-pandas-objects-dataframes)\n",
    "* [Setting Up Your First Data Science Project](intro_pandas.md#setting-up-our-first-data-science-project)\n",
    "\n",
    "## Capabilities of Pandas\n",
    "* Robust IO tools to reading from flat files (CSV and TXT), JSON, XML, Excel files, SQL tables, and other databases.\n",
    "* Inserting and deleting columns in DataFrame and higher dimensional objects\n",
    "* Handling missing data in both floating point and non-floating point data sets\n",
    "* Merging & joining datasets\n",
    "* Reshaping and pivoting datasets\n",
    "* Conditional data sorting and filtering\n",
    "* Iterating through data sets\n",
    "* Aggregating and transforming data sets with split-apply-combine operations from the group by engine\n",
    "* Automatic and explicit aligning and manipulating of high-dimensional data structures via hierarchical labeling and axis indexing\n",
    "* Subsetting, fancy indexing, and label-based slicing large data sets\n",
    "* Time-series functionality such as date range generation, date shifting, lagging, frequency conversions, moving window statistics, and moving window linear regressions.\n",
    "\n",
    "## NumPy ndarray Objects\n",
    "\n",
    "Because Pandas is built on top of NumPy, new users should first understand one NumPy data object that often appears within Pandas objects - the `ndarray`.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mottaquikarim/PythonProgramming/master/assets/numpy_ndarrays.png\" style=\"margin: 0 auto; display: block;\"/>\n",
    "\n",
    "An **ndarray, or N-dimensional array,** is a data type from the NumPy library. Ndarrays are deceptively similar to the more general Python `list` type we've been working with. An `ndarray` type is a group of elements, which can be accessed and updated using a zero-based index. Sounds exactly like a `list`, right? You can create and print an ndarray exactly like a list. You can even create an ndarray *from* a list like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "listA = [1, 2, 3]\n",
    "arrayA = np.array([1, 2, 3])\n",
    "print(listA) # [1, 2, 3]\n",
    "print(arrayA) # [1 2 3]\n",
    "\n",
    "listB = ['a', 'b', 'c']\n",
    "arrayB = np.array(listB)\n",
    "print(listB) # ['a', 'b', 'c']\n",
    "print(arrayB) # ['a' 'b' 'c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "However, there are several important differences to remember:\n",
    "\n",
    "First, all ndarrays are homogenous.* All elements in an ndarray must be the same data type (e.g. integers, floats, strings, booleans, etc.). If you try to enter data that is not homogenous, the `.array()` function will force unity of data type. Side note - notice that ndarrays get printed out without commas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arrayC = np.array([1, 'b', True])\n",
    "print(arrayC) # ['1', 'b', 'True']\n",
    "\n",
    "arrayD = np.array([1, False])\n",
    "print(arrayD) # [1 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Second, ndarrays have a parameter called `ndmin`, which allows you to specify the number of dimensions you want for your array when you create it. Here are the three key takeaways from the examples of this below.\n",
    "* Notice how each dimension prints on its own line, so the ndarray looks more like a *grid* than a single list.\n",
    "* `arrayE1` and `arrayE2` above are identical. This illustrates that the `nddim` parameter is optional. In other words, you can directly pass in multi-dimensional data without having to enter an argument for it.\n",
    "* `arrayF` throws an error because it's missing one vital piece of syntax that `arrayC1` has. Do you see it? The first parameter in the `.array()` method is the object (i.e. the values you want contained in the array). When you pass values for multiple dimensions of the array object into the `.array()` method, you separate them with commas. *You have to make sure you group the dimensions and their values into a single group by adding `()` around them.* If you don't, the `.array()` method might mistake the second dimension and its values for the second *parameter* of the `.array()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arrayE1 = np.array(([1, 2, 3], [4, 5, 6]))\n",
    "print(arrayC1)\n",
    "\"\"\"\n",
    "[[1 2 3]\n",
    " [4 5 6]]\n",
    "\"\"\"\n",
    "\n",
    "arrayE2 = np.array(([1, 2, 3], [4, 5, 6]), ndmin = 2)\n",
    "print(arrayC2)\n",
    "\"\"\"\n",
    "[[1 2 3]\n",
    " [4 5 6]]\n",
    "\"\"\"\n",
    "\n",
    "arrayF = np.array([1, 2, 3], [4, 5, 6])\n",
    "print(arrayF) # Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The third, and most important, difference between an array and a list is, *ndarrays are designed to handle **vectorized** operations* while a python list is not. In other words, if you apply a function to an ndarray object, the program will perform said function on each item in the array individually. If you apply a function to a list, the function to be performed on the list object as a whole.As a bonus, these vectorization capabilities also allow ndarrays take up less memory space and run faster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "listG = [1, 2, 3]\n",
    "arrayG = np.array(listA)\n",
    "\n",
    "print(arrayG + 2) # [3 4 5]\n",
    "print(listG + 2) # Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Creating Random & Range ndarrays\n",
    "\n",
    "There are a handful of other ways to create ndarrays, including random generation...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Create an array of 5 random integers between 50 and 100. They will form a uniform distribution.\n",
    "rand_array1 = np.random.randint(50,  100,  5)\n",
    "print(rand_array1) # [54 86 91 61 90]\n",
    "\n",
    "# Create a matrix of 2 rows and 3 columns, with all values between -1 and 1.\n",
    "rand_array2 = np.random.rand(2, 3)\n",
    "print(rand_array2)\n",
    "\"\"\"\n",
    "[[0.11298458 0.49065597 0.14219546]\n",
    " [0.27545168 0.87526704 0.93213146]]\n",
    "\"\"\"\n",
    "\n",
    "# Create a matrix of 2 rows and 3 columns, with all values between 0 and 1. They will form a normal distribution.\n",
    "rand_array3 = np.random.randn(2, 3)\n",
    "print(rand_array3)\n",
    "\"\"\"\n",
    "[[-0.24525306  1.9082735   0.55667231]\n",
    " [-1.17418436  0.12749887 -1.47157527]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "...and via the `.arange()` method. This method takes the start point of the array, the end point, and (optionally) the step size. Remember that the final value will actually be one less than the specified end point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_array = np.arange(2, 8, 2)\n",
    "print(range_array) # [2, 4, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Basic Pandas Objects: Index\n",
    "\n",
    "We know about the concept of an `index` from basic Python `lists`. Well, Pandas considers `Index` to be its own class of objects because you can customize an index in Pandas. As formally defined in the Pandas docs, an `index` object is an \"immutable ndarray implementing an ordered, sliceable set\" which is the default object for \"storing axis labels for all pandas objects\".\n",
    "\n",
    "## Basic Pandas Objects: Series\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mottaquikarim/PythonProgramming/master/assets/pd_series.png\" style=\"margin: 0 auto; display: block;\"/>\n",
    "\n",
    "A **Series** is a 1-D array of data just like the Python `list` datatype we've been working with, but it's a bit more flexible. Some notable characteristics include:\n",
    "\n",
    "* A Series is like a dict in that you can get and set values by index label.\n",
    "* A Pandas `Series` acts very similarly to a NumPy `ndarray`:\n",
    "\t* Just like ndarrays, looping through a Series value-by-value is usually not necessary because of its capability to handle vectorized operations.\n",
    "* The Pandas Series does have some distinct differences from an ndarray:\n",
    "\t* A Series can only have one dimension.\n",
    "\t* Operations between Series automatically align the data based on index label.\n",
    "\n",
    "Here's the general syntax for creating a Series:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series(data, index = index, dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* The `data` parameter can intake a Python dict, an ndarray, or a scalar value (like 5, 7.5, True, or 'a').\n",
    "* By default, the `index` parameter assigns an zero-based index to each element in data much like a regular Python `list`. Again though, you can pass custom index values to a `Series` to serve as axis labels for your data. Note that Pandas DOES support *non-unique* index values. \n",
    "* `dtype` specifies the type of data you're passing into your Series. If you leave this blank, the program will infer the `dtype` from the contents of the `data` parameter.\n",
    "\n",
    "Using this syntax, you can instantiate a Series from a single scalar value, a list, an ndarray, or a dict. *Note:* If `data` is an `ndarray`, `index` must be the same length as `data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# From a single scalar value\n",
    "s_scalar = pd.Series(5., index=['a', 'b', 'c', 'd', 'e'])\n",
    "\"\"\"\n",
    "a    5.0\n",
    "b    5.0\n",
    "c    5.0\n",
    "d    5.0\n",
    "e    5.0\n",
    "\"\"\"\n",
    "\n",
    "# From a list\n",
    "s_list = pd.Series(['red','orange','yellow','green','blue','purple'])\n",
    "\"\"\"\n",
    "0       red\n",
    "1    orange\n",
    "2    yellow\n",
    "3     green\n",
    "4      blue\n",
    "5    purple\n",
    "\"\"\"\n",
    "\n",
    "# From an ndarray\n",
    "s_ndarray = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])\n",
    "print(s_ndarray)\n",
    "\"\"\"\n",
    "a   -0.901847\n",
    "b   10.503150\n",
    "c    2.060891\n",
    "d   -0.367695\n",
    "e    1.040442\n",
    "\"\"\"\n",
    "\n",
    "# From a dict\n",
    "d = {'b': 1, 'a': 0, 'c': 2} ### use wines from data set\n",
    "s_dict = pd.Series(d)\n",
    "\"\"\"\n",
    "b    1\n",
    "a    0\n",
    "c    2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Basic Pandas Objects: DataFrames\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mottaquikarim/PythonProgramming/master/assets/pd_dataframe.png\" style=\"margin: 0 auto; display: block;\"/>\n",
    "\n",
    "\n",
    "A **DataFrame** is a two-dimensional data matrix that stores data much like a spreadsheet does. It has labeled columns and rows with values for each column. Basically, it's virtual spreatsheet. It accepts many different data types as values, including strings, arrays (lists), dicts, Series, and even other DataFrames. The general syntax for creating a DataFrame is identical to that of a Series except it includes a second index parameter called `columns` parameter for adding the index values to the second dimension:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame (data, index, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Creating a DataFrame is a little more complex than creating a Series because you have to consider both `rows` and `columns`. Aside from creating a dataframe indirectly by importing an existing data structure, you can create a DataFrame by:\n",
    "\n",
    "* Specifying column names (i.e. column index values) directly within the `data` parameter\n",
    "* Specifying column names separately in the `columns` parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Specify values for each column.\n",
    "df = pd.DataFrame(\n",
    "{\"a\" : [4 ,5, 6],\n",
    "\"b\" : [7, 8, 9],\n",
    "\"c\" : [10, 11, 12]},\n",
    "index = [1, 2, 3])\n",
    "\n",
    "# Specify values for each row.\n",
    "df = pd.DataFrame(\n",
    "[[4, 7, 10],\n",
    "[5, 8, 11],\n",
    "[6, 9, 12]],\n",
    "index=[1, 2, 3],\n",
    "columns=['a', 'b', 'c'])\n",
    "\n",
    "\n",
    "# Both of these methods create a DataFrame with these values:\n",
    "\"\"\"\n",
    "   a   b   c\n",
    "1  4   7   10\n",
    "2  5   8   11\n",
    "3  6   9   12\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here are a few other examples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# From dict of Series or dicts\n",
    "data1 = {'one': pd.Series([1., 2., 3.], index=['a', 'b', 'c']), 'two': pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}\n",
    "df1 = pd.DataFrame(data1, index=['d', 'b', 'a'], columns=['two', 'three'])\n",
    "\"\"\"\n",
    "   two three\n",
    "d  4.0   NaN\n",
    "b  2.0   NaN\n",
    "a  1.0   NaN\n",
    "\"\"\"\n",
    "\n",
    "# From dict of ndarrays / lists\n",
    "data2 = {'one': [1., 2., 3., 4.],'two': [4., 3., 2., 1.]}\n",
    "df2 = pd.DataFrame(data2, index=['a', 'b', 'c', 'd'])\n",
    "\"\"\"\n",
    "   one  two\n",
    "a  1.0  4.0\n",
    "b  2.0  3.0\n",
    "c  3.0  2.0\n",
    "d  4.0  1.0\n",
    "\"\"\"\n",
    "\n",
    "# From a list of dicts\n",
    "data3 = [{'a': 1, 'b': 2}, {'a': 5, 'b': 10, 'c': 20}]\n",
    "df3 = pd.DataFrame(data3, index=['first', 'second'], columns=['a', 'b', 'c'])\n",
    "\"\"\"\n",
    "        a   b     c\n",
    "first   1   2   NaN\n",
    "second  5  10  20.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setting Up Your First Data Science Project\n",
    "\n",
    "Before we dive into analysis, we have to make sure we set up a stable, organized environment. For our lesson on Pandas we'll be using this dataset:\n",
    "\n",
    "[Wine Reviews | Kaggle](https://www.kaggle.com/zynicide/wine-reviews/) -- \n",
    "*130k wine reviews with variety, location, winery, price, & description*\n",
    "\n",
    "Instead of convoluting things with a specialized Data Science IDE, we're going to start simple -- working locally, straight in the terminal. We'll walk through how to spin this up together step by step:\n",
    "\n",
    "**1)** On your Desktop, create a new folder called \"WineReviews\". In here, we want to split up our code files from our raw data files to keep things organized.\n",
    "\n",
    "**2)** Within this parent directory, create an empty \"main.py\" file.\n",
    "\n",
    "**3)** Now, create another folder called \"raw_data\". Drag the `wine_reviews.csv` file into it.\n",
    "\n",
    "**4)** Go back to the main.py file. In practice, when we go to run the main.py file in terminal, the code we'll write here will open the csv file and give the program access to its full contents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# B) Read csv file\n",
    "wine_reviews = pd.read_csv('raw_data/winemag-data-130k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "First, notice that the standard is to import numpy and pandas into your python program as `np` and `pd`. Second, when you write the command to open the file, make sure you put the file name in quotes and reference the path to its location in the project directory.\n",
    "\n",
    "**5)** Open up your terminal and `cd` into our project's parent directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/Desktop/WineReviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "**6)** Create your virtual environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 -m venv .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "**7)** Activate the virtual environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source .env/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "**8)** Install Pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "There are a couple salient points to mention here:\n",
    "\n",
    ">> * **Remember** that we installed Python3 in our high-level system environment, but you don't want to do that with more specific libraries. It could cause you to run into issues if a certain version references older iterations of that library. \n",
    ">> * For the `WineReviews` project, you will only have to install Pandas once. Every time you reactivate this project's virtual environment, it will have it there.\n",
    ">> * Having NumPy installed is a pre-requisite for using Pandas. However, installing Pandas automatically installs NumPy. That's why we don't have to call `pip install numpy` explicitly.\n",
    "\n",
    "**9)** Run the main.py file to make sure the code works!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 main.py"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
