{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mottaquikarim/PYTH2/blob/master/src/Topics/nb/preprocessing.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis w/üêºüêº\n",
    "\n",
    "For today's lesson, we will leverage Pandas for exploratory data analysis (EDA).\n",
    "We will use Pandas to investigate, wrangle, munge, and clean our data.\n",
    "\n",
    "In particular, we will examine how Pandas can be used to:\n",
    "\n",
    "* **Investigate a dataset's integrity**\n",
    "* **Filter, sort, and manipulate a DataFrame's series**\n",
    "\n",
    "Additionally, the end portion of this section contains a glossary of methods and attributes provided by Pandas to handle data wrangling, selection, cleaning and organizing.\n",
    "\n",
    "* **[Wrangling Data](preprocessing.md#wrangling-data)**\n",
    "* **[Selecting Data](preprocessing.md#selecting-data)**\n",
    "\t* **[Single Values](preprocessing.md#single-values)**\n",
    "\t* **[Subsetting & Slicing](preprocessing.md#subsetting--slicing)**\n",
    "* **[Cleaning & Organizing Data](preprocessing.md#cleaning--organizing-data)**\n",
    "\t* **[Editing](preprocessing.md#editing)**\n",
    "\t* **[Null Values](preprocessing.md#null-values)**\n",
    "\t* **[Duplicates](preprocessing.md#duplicates)**\n",
    "\t* **[Sorting](preprocessing.md#sorting)**\n",
    "\n",
    "## Data sets\n",
    "\n",
    "* **[Wine Reviews | Kaggle](https://www.kaggle.com/zynicide/wine-reviews/)**\n",
    "\t* *130k wine reviews with variety, location, winery, price, and description* \n",
    "* **[Wine Reviews | Local](https://raw.githubusercontent.com/mottaquikarim/PythonProgramming/master/raw_data/winemag-data-130k-v2.csv)**\n",
    "\t* *You can download a version of the kaggle dataset directly from this Github Repo* \n",
    "* **[Adventureworks Cycles | Local](https://raw.githubusercontent.com/mottaquikarim/PythonProgramming/master/raw_data/production.product.tsv)**\n",
    "\t* *You can download a version of the Adventureworks Cycles dataset directly from this Github Repo* \n",
    "\n",
    "\n",
    "## Adventureworks Cycles\n",
    "\n",
    "Our core focus will be using a dataset developed by Microsoft for training purposes in SQL server, known the Adventureworks Cycles 2014OLTP Database.\n",
    "\n",
    "* It is based on a fictitious company called Adventure Works Cycles (AWC), a multinational manufacturer and seller of bicycles and accessories.\n",
    "* The company is based in Bothell, Washington, USA and has regional sales offices in several countries.\n",
    "* We will be looking at a single table from this database, the Production.Product table, which outlines some of the products this company sells.\n",
    "\n",
    "### Loading the Data\n",
    "\n",
    "We can load our data as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "prod = pd.read_csv('/raw_data/production.product.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note the `sep='\\t'`; this is because we are pulling in a `tsv` file, which is basically a csv file but with `tabs` as delimiters vs commas.\n",
    "\n",
    "**YOU DO**: Download the `tsv` file into your local machine, create a python virtualenv and run the code above, but on your machine.\n",
    "\n",
    "\n",
    "\n",
    "### Data dictionary\n",
    "\n",
    "Every good dataset has a **data dictionary**. Essentially, it lists each field in the data and provides a contextual description. It serves as a good frame of reference for anyone not diving directly into the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = prod.columns\n",
    "for idx, col in enumerate(cols):\n",
    "  print(idx+1, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    1 ProductID\n",
    "    2 Name\n",
    "    3 ProductNumber\n",
    "    4 MakeFlag\n",
    "    5 FinishedGoodsFlag\n",
    "    6 Color\n",
    "    7 SafetyStockLevel\n",
    "    8 ReorderPoint\n",
    "    9 StandardCost\n",
    "    10 ListPrice\n",
    "    11 Size\n",
    "    12 SizeUnitMeasureCode\n",
    "    13 WeightUnitMeasureCode\n",
    "    14 Weight\n",
    "    15 DaysToManufacture\n",
    "    16 ProductLine\n",
    "    17 Class\n",
    "    18 Style\n",
    "    19 ProductSubcategoryID\n",
    "    20 ProductModelID\n",
    "    21 SellStartDate\n",
    "    22 SellEndDate\n",
    "    23 DiscontinuedDate\n",
    "    24 rowguid\n",
    "    25 ModifiedDate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Reading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "The `head` method lets us read in the **first n rows** of a dataset. Run this in your machine, you should expect to see:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ProductID             Name ProductNumber  MakeFlag  ...  SellEndDate DiscontinuedDate                                 rowguid                   ModifiedDate\n",
    "0          1  Adjustable Race       AR-5381         0  ...          NaN              NaN  {694215B7-08F7-4C0D-ACB1-D734BA44C0C8}  2014-02-08 10:01:36.827000000\n",
    "\n",
    "[1 rows x 25 columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **YOU DO**: Run the above code in *your* machine, but with **n=5**. What do you see?\n",
    "* **YOU DO**: What kind of object is `prod`? Run `type(prod)` and report back your findings.\n",
    "* **YOU DO**: What is the shape of this dataframe? Run `prod.shape` to find out.\n",
    "\n",
    "## DataFrame subsets\n",
    "\n",
    "This dataset is comprehensive! Let's see how we might be able to select a *subset* of this data for easier analysis.\n",
    "\n",
    "Let's start with only 3 rows for now:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_subset = prod.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ProductID             Name ProductNumber  MakeFlag  ...  SellEndDate DiscontinuedDate                                 rowguid                   ModifiedDate\n",
    "0          1  Adjustable Race       AR-5381         0  ...          NaN              NaN  {694215B7-08F7-4C0D-ACB1-D734BA44C0C8}  2014-02-08 10:01:36.827000000\n",
    "1          2     Bearing Ball       BA-8327         0  ...          NaN              NaN  {58AE3C20-4F3A-4749-A7D4-D568806CC537}  2014-02-08 10:01:36.827000000\n",
    "2          3  BB Ball Bearing       BE-2349         1  ...          NaN              NaN  {9C21AED2-5BFA-4F18-BCB8-F11638DC2E4E}  2014-02-08 10:01:36.827000000\n",
    "\n",
    "[3 rows x 25 columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If we wanted to only pull in a few **columns**, we could do something like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_cols = prod_subset[['ProductID', 'Name']]\n",
    "print(two_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ProductID             Name\n",
    "0          1  Adjustable Race\n",
    "1          2     Bearing Ball\n",
    "2          3  BB Ball Bearing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **YOU DO**: Grab the first **5** rows of the dataset and save a subset df with the following columns: **ProductID**, **Name**, **Color**, and **ListPrice**.\n",
    "\n",
    "## Column headers and datatypes\n",
    "\n",
    "We can leverage pandas to explore the column header names and associated datatypes of the headers as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prod.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Index(['ProductID', 'Name', 'ProductNumber', 'MakeFlag', 'FinishedGoodsFlag',\n",
    "       'Color', 'SafetyStockLevel', 'ReorderPoint', 'StandardCost',\n",
    "       'ListPrice', 'Size', 'SizeUnitMeasureCode', 'WeightUnitMeasureCode',\n",
    "       'Weight', 'DaysToManufacture', 'ProductLine', 'Class', 'Style',\n",
    "       'ProductSubcategoryID', 'ProductModelID', 'SellStartDate',\n",
    "       'SellEndDate', 'DiscontinuedDate', 'rowguid', 'ModifiedDate'],\n",
    "      dtype='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If we wanted to view the columns and their types, we can do:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductID                  int64\n",
    "Name                      object\n",
    "ProductNumber             object\n",
    "MakeFlag                   int64\n",
    "FinishedGoodsFlag          int64\n",
    "Color                     object\n",
    "SafetyStockLevel           int64\n",
    "ReorderPoint               int64\n",
    "StandardCost             float64\n",
    "ListPrice                float64\n",
    "Size                      object\n",
    "SizeUnitMeasureCode       object\n",
    "WeightUnitMeasureCode     object\n",
    "Weight                   float64\n",
    "DaysToManufacture          int64\n",
    "ProductLine               object\n",
    "Class                     object\n",
    "Style                     object\n",
    "ProductSubcategoryID     float64\n",
    "ProductModelID           float64\n",
    "SellStartDate             object\n",
    "SellEndDate               object\n",
    "DiscontinuedDate         float64\n",
    "rowguid                   object\n",
    "ModifiedDate              object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **YOU DO**: What kind of python object is the `prod.dtypes`? How do you know?\n",
    "* **YOU DO**: How does pandas know the col datatypes? Don't code this, but how might you implement this feature in pure python?\n",
    "\n",
    "## Column Selection\n",
    "\n",
    "**IMPORTANT**: depending on number of square brackets used, selection of a column may return a **Series** object or a **DataFrame** object. Depending on your usecase, you may *want* one or the other!\n",
    "\n",
    "Consider the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod['Name'].head(3)\n",
    "type(prod['Name'].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0    Adjustable Race\n",
    "1       Bearing Ball\n",
    "2    BB Ball Bearing\n",
    "Name: Name, dtype: object\n",
    "<class 'pandas.core.series.Series'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "vs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod[[\"Name\"]].head(3)\n",
    "type(prod[['Name']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "              Name\n",
    "0  Adjustable Race\n",
    "1     Bearing Ball\n",
    "2  BB Ball Bearing\n",
    "<class 'pandas.core.frame.DataFrame'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **YOU DO**: Select **Name** and **ProductID** columns from our Dataframe. Is this possible to do as a **Series**? Why or why not?\n",
    "\n",
    "## Renaming Columns\n",
    "\n",
    "We can rename columns as needed, like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prod = prod.rename(columns={'Name': 'ProductName', 'ProductNumber':'Number'}, inplace=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A few things to note here:\n",
    "\n",
    "* `inplace`: this is a boolean that will update the **original** dataframe OR create us a new one\n",
    "* `{'Name': 'ProductName'}`: we may use this as a way to map a new col name to an existing one\n",
    "\n",
    "**REMEMBER**: we can view all the columns of a dataframe with:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "What is the datatype of this attribute?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(prod.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<class 'pandas.core.indexes.base.Index'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The **Index** is an immutable ndarray implementing an ordered, sliceable set. It is the basic object storing axis labels for all pandas objects. Think of it as a 'row address' for your data frame (table). We can cast this `Index` to be something like, like say...a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(prod.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, we can do something like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_list = list(prod.columns)\n",
    "cols_list[0] = 'New Col'\n",
    "prod.columns = cols_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **YOU DO**: What will the code above do? Run it and report back.\n",
    "* **YOU DO**: Select the first three rows under `New Col` and return it as a **dataframe**.\n",
    "* **YOU DO**: First, copy `prod` to `prod_cpy` (look at references below to see how to copy a dataframe). Then, rename the columns above, but **inplace** meaning `prod_cpy` itself must be mutated.\n",
    "\n",
    "## Basic Stats on Columns\n",
    "\n",
    "Five Number Summary (all assumes numeric data):\n",
    "- **Min:** The smallest value in the column\n",
    "- **Max:** The largest value in the column\n",
    "- **Quartile:** A quartile is one fourth of our data\n",
    "    - **First quartile:** This is the bottom most 25 percent\n",
    "    - **Median:** The middle value. (Line all values biggest to smallest - median is the middle!) Also the 50th percentile\n",
    "    - **Third quartile:** This the the top 75 percentile of our data\n",
    "\n",
    "![](https://www.mathsisfun.com/data/images/quartiles-a.svg)\n",
    "\n",
    "The `describe` method allows us to achieve this with pandas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note - describe *default* only checks numeric datatypes\n",
    "prod[['MakeFlag', 'SafetyStockLevel', 'StandardCost']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If we were to select cols as series, we could run additional **Series** object methods:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the most popular product colors (aggregated by count, descending by default)\n",
    "prod['Color'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Black           93\n",
    "Silver          43\n",
    "Red             38\n",
    "Yellow          36\n",
    "Blue            26\n",
    "Multi            8\n",
    "Silver/Black     7\n",
    "White            4\n",
    "Grey             1\n",
    "Name: Color, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **YOU DO**: Leveraging the `unique` **Series** method, print out the unique colors for this product.\n",
    "* **YOU DO**: Leveraging the `nunique` **Series** method, print out how many distinct colors are available.\n",
    "* **YOU DO**: Leveraging the `dropna` keyword arg of the `nunique` **Series** method, print out how many distinct colors are available *including* **NULL** values.\n",
    "\n",
    "## Filtering\n",
    "\n",
    "Filtering and sorting are key processes that allow us to drill into the 'nitty gritty' and cross sections of our dataset.\n",
    "\n",
    "To filter, we use a process called **Boolean Filtering**, wherein we define a Boolean condition, and use that Boolean condition to filer on our DataFrame.\n",
    "\n",
    "Recall: our given dataset has a column `Color`. Let's see if we can find all products that are `Black`. Let's take a look at the first 10 rows of the dataframe to see how it looks as-is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = prod['Color'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductID\n",
    "1         NaN\n",
    "2         NaN\n",
    "3         NaN\n",
    "4         NaN\n",
    "316       NaN\n",
    "317     Black\n",
    "318     Black\n",
    "319     Black\n",
    "320    Silver\n",
    "321    Silver\n",
    "Name: Color, dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To find only the \"Black\" colored items, we can:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod['Color'].head(10) == 'Black'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductID\n",
    "1      False\n",
    "2      False\n",
    "3      False\n",
    "4      False\n",
    "316    False\n",
    "317     True\n",
    "318     True\n",
    "319     True\n",
    "320    False\n",
    "321    False\n",
    "Name: Color, dtype: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **YOU DO**: Without using the `unique`/`nunique` methods from above, can you apply an additional filter to the series above to determine how many `Black` colored products exist?\n",
    "\n",
    "We can apply this filtering to our Dataframes as well, in a more interesting manner:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod[prod['Color'] == 'Black'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ProductID         Name ProductNumber  MakeFlag  ...  SellEndDate DiscontinuedDate                                 rowguid                   ModifiedDate\n",
    "5        317  LL Crankarm       CA-5965         0  ...          NaN              NaN  {3C9D10B7-A6B2-4774-9963-C19DCEE72FEA}  2014-02-08 10:01:36.827000000\n",
    "6        318  ML Crankarm       CA-6738         0  ...          NaN              NaN  {EABB9A92-FA07-4EAB-8955-F0517B4A4CA7}  2014-02-08 10:01:36.827000000\n",
    "7        319  HL Crankarm       CA-7457         0  ...          NaN              NaN  {7D3FD384-4F29-484B-86FA-4206E276FE58}  2014-02-08 10:01:36.827000000\n",
    "\n",
    "[3 rows x 25 columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **YOU DO**: Slice the dataframe above and select only the `Color` column - is there any non `black` color items?\n",
    "* **YOU DO**: calculate the average **ListPrice** for the salable products (**hint**: use the `FinishedGoodsFlag` column to determine \"salability\") using the **Series**.`mean()` method\n",
    "* **YOU DO**: calculate the above again, but this time use `describe` and pull the `mean` from there.\n",
    "\n",
    "## Compound Filtering\n",
    "\n",
    "Let's filter on _multiple conditions_. Before, we filtered on rows where `Color` was `Black`. We also filtered where `FinishedGoodsFlag` was equal to `1`. Let's see what happens when we filter on *both* simultaneously. \n",
    "\n",
    "The format for multiple conditions is:\n",
    "\n",
    "`df[ (df['col1'] == value1) & (df['col2'] == value2) ]`\n",
    "\n",
    "Or, more simply:\n",
    "\n",
    "`df[ (CONDITION 1) & (CONDITION 2) ]`\n",
    "\n",
    "Which eventually may evaluate to something like:\n",
    "\n",
    "`df[ True & False ]`\n",
    "\n",
    "...on a row-by-row basis. If the end result is `False`, the row is omitted.\n",
    "\n",
    "**Don't forget parentheses in your conditions!!** This is a common mistake.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod[ (prod['Color'] == 'Black') & (prod['FinishedGoodsFlag'] == 1) ].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     ProductID                       Name ProductNumber  MakeFlag  ...  SellEndDate DiscontinuedDate                                 rowguid                   ModifiedDate\n",
    "209        680  HL Road Frame - Black, 58    FR-R92B-58         1  ...          NaN              NaN  {43DD68D6-14A4-461F-9069-55309D90EA7E}  2014-02-08 10:01:36.827000000\n",
    "212        708    Sport-100 Helmet, Black       HL-U509         0  ...          NaN              NaN  {A25A44FB-C2DE-4268-958F-110B8D7621E2}  2014-02-08 10:01:36.827000000\n",
    "226        722  LL Road Frame - Black, 58    FR-R38B-58         1  ...          NaN              NaN  {2140F256-F705-4D67-975D-32DE03265838}  2014-02-08 10:01:36.827000000\n",
    "\n",
    "[3 rows x 25 columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Another example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have an example of a list price of greater than 50, \n",
    "# OR a product size that is not equal to 'XL'\n",
    "\n",
    "prod[ (prod['ListPrice'] > 50) | (prod['Size'] != 'XL') ].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ProductID             Name ProductNumber  MakeFlag  ...  SellEndDate DiscontinuedDate                                 rowguid                   ModifiedDate\n",
    "0          1  Adjustable Race       AR-5381         0  ...          NaN              NaN  {694215B7-08F7-4C0D-ACB1-D734BA44C0C8}  2014-02-08 10:01:36.827000000\n",
    "1          2     Bearing Ball       BA-8327         0  ...          NaN              NaN  {58AE3C20-4F3A-4749-A7D4-D568806CC537}  2014-02-08 10:01:36.827000000\n",
    "2          3  BB Ball Bearing       BE-2349         1  ...          NaN              NaN  {9C21AED2-5BFA-4F18-BCB8-F11638DC2E4E}  2014-02-08 10:01:36.827000000\n",
    "\n",
    "[3 rows x 25 columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **YOU DO**: Find all rows that have a **NULL** dataframe and is **NOT** finished. **HINT**: use `pd.isna`\n",
    "\n",
    "## Sorting\n",
    "\n",
    "Here's how we can sort a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.sort_values(by='StandardCost', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     ProductID              Name ProductNumber  MakeFlag  ...          SellEndDate DiscontinuedDate                                 rowguid                   ModifiedDate\n",
    "253        749  Road-150 Red, 62    BK-R93R-62         1  ...  2012-05-29 00:00:00              NaN  {BC621E1F-2553-4FDC-B22E-5E44A9003569}  2014-02-08 10:01:36.827000000\n",
    "254        750  Road-150 Red, 44    BK-R93R-44         1  ...  2012-05-29 00:00:00              NaN  {C19E1136-5DA4-4B40-8758-54A85D7EA494}  2014-02-08 10:01:36.827000000\n",
    "255        751  Road-150 Red, 48    BK-R93R-48         1  ...  2012-05-29 00:00:00              NaN  {D10B7CC1-455E-435B-A08F-EC5B1C5776E9}  2014-02-08 10:01:36.827000000\n",
    "\n",
    "[3 rows x 25 columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This one is a little more advanced, but it demonstrates a few things:\n",
    "- Conversion of a `numpy.ndarray` object (return type of `pd.Series.unique()`) into a `pd.Series` object\n",
    "- `pd.Series.sort_values` with the `by=` kwarg omitted (if only one column is the operand, `by=` doesn't need specified\n",
    "- Alphabetical sort of a string field, `ascending=True` means A->Z\n",
    "- Inclusion of nulls, `NaN` in a string field (versus omission with a float/int as prior example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(prod['Color'].unique()).sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1           Black\n",
    "5            Blue\n",
    "8            Grey\n",
    "6           Multi\n",
    "3             Red\n",
    "2          Silver\n",
    "9    Silver/Black\n",
    "4           White\n",
    "7          Yellow\n",
    "0             NaN\n",
    "dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## A few final YOU DOs\n",
    "\n",
    "* **YOU DO**: Create a variable called `rows` and a variable called `cols`. Store the num rows and cols in dataframe into these variables, respectively\n",
    "* **YOU DO**: Print out the number of unique product lines that exist in this data set\n",
    "* **YOU DO**: Print out the values of these product lines, **DROP NULLS**\n",
    "* **YOU DO**: Using `shape` and a dataframe filter, print out how many `R` productlines exist.\n",
    "* **Challenge**: What are the top 3 most expensive list price product that are either in the Women's Mountain category, OR Silver in Color? Return your answer as a DataFrame object, with NewName relabeled as Name, and ListPrice columns. Perform the statement in one execution, and do not mutate the source DataFrame.\n",
    "\n",
    "## Recap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# basic DataFrame operations\n",
    "df.head()\n",
    "df.tail()\n",
    "df.shape\n",
    "df.columns\n",
    "df.Index\n",
    "\n",
    "# selecting columns\n",
    "df.column_name\n",
    "df['column_name']\n",
    "\n",
    "# renaming columns\n",
    "df.rename({'old_name':'new_name'}, inplace=True)\n",
    "df.columns = ['new_column_a', 'new_column_b']\n",
    "\n",
    "# notable columns operations\n",
    "df.describe() # five number summary\n",
    "df['col1'].nunique() # number of unique values\n",
    "df['col1'].value_counts() # number of occurrences of each value in column\n",
    "\n",
    "# filtering\n",
    "df[ df['col1'] < 50 ] # filter column to be less than 50\n",
    "df[ (df['col1'] == value1) & (df['col2'] > value2) ] # filter column where col1 is equal to value1 AND col2 is greater to value 2\n",
    "\n",
    "# sorting\n",
    "df.sort_values(by='column_name', ascending = False) # sort biggest to smallest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "üêº üêº üêº\n",
    "\n",
    "## DataFrame Reference\n",
    "\n",
    "Please find below a list of useful dataframe properties and methods for use in your exploratory data analysis practice.\n",
    "\n",
    "## Wrangling Data\n",
    "\n",
    "Given the following dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews = pd.read_csv('raw_data/winemag-data-130k.csv')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
